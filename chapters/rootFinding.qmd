---
jupyter: python3
reference-location: margin
citation-location: margin
execute: 
  freeze: auto
---

# Root Finding and Optimization Algorithms

[Jupyter Notebook](https://lancejnelson.github.io/PH135/jupyter/rootFinding.ipynb)

Often in science, we find ourselves wanting to do one of the following:  
1. Solve an equation for a specified variable
2. Find the zeros of a function (equivalent to solving an equation that is equal to zero)
3.Find the extrema (maxima or minima) of a function.

As an example, consider the function shown below

```{python}
#| echo: false
#| lst-cap: The zero(red dot), maximum (green dot), and minimum (blue dot) of a function are illustrated.
import matplotlib.pyplot as plt
import numpy as np

x = np.linspace(-0.5,3.5,100)
y = np.cos(x)
plt.plot(x,y,'b-')
plt.plot([1.5707],[0],'r.',ms = 15)
plt.plot([3.14],[-1.0],'b.',ms = 15)
plt.plot([0],[1],'g.',ms = 15)
plt.grid()
plt.show()
```


When the function of interest is unsolvable using standard algebraic techniques, we must resort to a numerical algorithm to find the solution.

<!--  Finding the zero of this function means finding the x-value where the function is equal to zero (red dot).  Finding the min or max of the function means finding the x value where the slope of the function is zero (blue and green dots). When algebra techniques fail to solve the equation, we can use one of several numerical algorithms to solve it instead. 
You probably remember being asked to find the roots of a function in your math class. Finding the roots means finding the x values that make $y(x) = 0$. For example, the following polynomial equation has two solutions that can be found using the quadratic formula.

$$
4 x^2 + 2x - 2 = 0
$$

The solutions to this equation are $-1$ and ${1\over 2}$. Try plugging them into the equation above to verify this. -->
In this chapter we will discuss various numerical methods for performing these tasks.   

## Bisection
The bisection method is a numerical algorithm for finding the zeros of a function, or the locations where the function is equal to zero. If you want to find the location where the function equals something other than zero, you can simply rearrange the function until a zero appears on the right hand side of the equation and proceed with bisection on the new function. 
The bisection method consists of choosing an interval wherein the function zero is found and then narrowing that interval through repeated evaluation of the function.  Formally, the algorithm proceeds as follows:  
1. Choose an interval wherein the function zero is certain to be located. Call the interval $(a,b)$
2. Calculate the midpoint of the interval $c = {a+ b \over 2}$
3. Calculate the function value at the midpoint ($f(c)$).
4. By examining the sign of $f(c)$ determine whether the interval $(a,c)$ or $(c,b)$ contains the zero of the function.
5. Repeat steps 2-4 until $f(c)$ is sufficiently small.

In the code cell below, try to use the bisection method to solve the following equation.
$$
y(x) = 5 x^2 - 3x - 2 = 0
$$
```{python}
import numpy as np
ab = [0,3]
y = lambda x: 5 * x**2 - 3 * x - 2
mid = ab[1]
while abs(y(mid)) > 1e-5:
  mid = (ab[0] + ab[1])/2
  
  if np.sign(y(mid)) == np.sign(ab[1]):
    ab = [ab[0],mid]
  else:
    ab = [mid,ab[1]]


print(mid)


```

![Used with permission from: https://commons.wikimedia.org/wiki/File:Bisection_method.svg](https://lancejnelson.github.io/PH135/figures/Bisection_method.png)

## Secant Method


## Newton's Method
Newton's method uses the slope of a function to find a better approximation to the zeros. By repeatedly using the slope of the function to find a better and better approximation to the zero, the algorithm can find the zero to a desired level of accuracy. The algorithm begins with an initial guess for the zero that need not be very close, but shouldn't be extremely far away either.  An improvement on this initial guess is calculated with
$$
x_1 = x_0 - {f(x_0)\over f'(x_0)}
$$
where $f'(x_0)$ is the derivative of the function evaluated at the initial guess.  The algorithm continues with repeated evaluation of the equation above until $f(x_n)$ evaluates to a sufficiently small number:

$$
x_n = x_{n-1} - {f(x_n)\over f'(x_n)}
$$

Below you will find a code example for solving the following equation:

$$
y(x) = \cos(x) = 0
$$

```{python}
import numpy as np

x = 2.3

while abs(np.cos(x)) > 1e-5:
  x = x + np.cos(x)/np.sin(x) 

print(x,np.cos(x))

```

If the function of interest has multiple zeros (like the cosine function we did above), one must give careful consideration to the initial guess.  Making a poor choice can lead to the algorithm finding a different zero than what was intended. 

![Used with permission from: https://commons.wikimedia.org/wiki/File:Newton_iteration.svg](https://lancejnelson.github.io/PH135/figures/Newtons_method.png)

## Fixed-Point Iteration
Suppose you want to solve the following equation:
$$
x = \cos(x)
$$
No matter how hard you try, you won't be able to solve this equation for $x$.  Instead, you'll need to use a numerical method called fixed-point iteration to solve it.  In this method, you begin with an initial guess and then repeatedly evaluate the function of interest until $|x - \cos(x)| $ is sufficiently small. 

```{python}
import numpy as np
x = 3
count = 0
while abs(x - np.cos(x)) > 1e-5:
  x = np.cos(x)
  count += 1
```


![Used with permission from: https://commons.wikimedia.org/wiki/File:Cosine_fixed_point.svg](https://lancejnelson.github.io/PH135/figures/Fixed_Point.png)

Fixed-point iteration can also be used to find the zeros or extrema of a function if you can first algebraically manipulate the equation to take the form shown in the equation above. For example, the following equation

$$
2x^3 - 2 x - 5 =0 
$$

Is equivalent to:
$$
x = (x+{5\over 2})^{1\over 3}
$$

```{python}
import numpy as np
x = 3
count = 0
while abs(x - (x+5/2)**(1/3)) > 1e-8:
    x = (x+5/2)**(1/3)
    count += 1
    if count > 10000:
        break

```


## Finding Extrema

Any of the methods discussed above can be used to find extrema by finding the zeros of the derivative.  For example, to find the minimum of this function:

$$
y(x) = 5 x^3 - 2x^2 - 8 x + 2 
$$

We can find the zeros of the derivative function:

$$
y'(x) = 15 x^2 - 4 x - 8
$$

Fixed-point iteration, or any of the other methods discussed, can then be used to solve this equation:


```{python}
import numpy as np
x = 3
count = 0
while abs(x - np.sqrt(4/15 * x + 8/15)) > 1e-8:
    x = np.sqrt(4/15 * x + 8/15)
    count += 1
    if count > 10000:
      print("Too many iterations. Results may not be correct!")
      break
print(x)

```


## Exercises
1. Use the bisection method to find the zeros of the function
$$
y(x) = 8x^3 - 15 x^2 - 4 x + 5
$$

Hint: This function has three zeros; one in the region [-1,0], one in the region [0,1] and another in the region [1.5,2.5]

2. Use Newton's method to find the zero for the following function (slightly different from the one in problem 1):
$$
y(x) = 8x^3 - 15 x^2 - 4 x - 5
$$
Answer: You should find that the zero is located at $\approx 2.2257$
3. Use fixed-point iteration to solve the following equation
$$
{1\over 2}^x = x^2
$$
4. Use Newton's method to solve the following equation
$$
e^x = \cos(x)
$$
Note: This function has three solutions; one in the region [-5,-4], one in the region [-2,-1] and another in the region [-1,1]. See if you can find all of them by varying your initial guess.